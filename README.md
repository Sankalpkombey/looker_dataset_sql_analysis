
# Looker Datset: Advanced SQL Analysis and Customer Segmentation

Project Category: Advanced [Click here to get dataset](https://www.kaggle.com/datasets/mustafakeser4/looker-ecommerce-bigquery-dataset)

<img src="https://github.com/Sankalpkombey/looker_dataset_sql_analysis/blob/main/looker_logo%20(1).png" height="800" weight="1000">

## Overview

This project involves analyzing an E-Commerce dataset with detailed attributes about customers, orders, order items, products, and revenue using PostgreSQL. It covers a full end-to-end analytics pipeline, including data modeling, advanced SQL querying, customer segmentation, and query optimization. The primary goals of this project are to demonstrate SQL expertise, extract actionable business insights, and optimize performance for scalability.

![EDR_diagram](https://github.com/Sankalpkombey/looker_dataset_sql_analysis/blob/main/Screenshot%202025-08-28%20020302.png)

## Project Steps

### 1. Data Exploration
Before writing queries, the dataset was carefully explored to understand key metrics:
- `Users`: Basic info such as name, email, and registration date.
- `Products`: Basic info about products, brand and retail price.
- `Orders`: Transaction details, revenue per order, and order statuses.
- `Order Items`: Order id, time shipped, sale price
- `Inventory Items`: Product available, product id, product distribution
- `events`: traffic source, ip iddress, postal code
- `distribution centers`: Location-based fulfillment data.

### 2. Querying the Data

After the data is inserted, various SQL queries can be written to explore and analyze the data. Queries are categorized into **easy**, **medium**, and **advanced** levels to help progressively develop SQL proficiency.

#### Easy Queries
- Simple data retrieval, filtering, and basic aggregations.
  
#### Medium Queries
- More complex queries involving grouping, aggregation functions, and joins.
  
#### Advanced Queries
- Nested subqueries, window functions, CTEs, and performance optimization.

### 4. Customer Segmentation
Customer segmentation is a crucial part of the project where customers are grouped based on their lifetime value, transaction patterns, and engagement metrics.

- Percentile-based segmentation is applied to classify customers into low-value, mid-value, and high-value groups.
  
- Insights are generated by analyzing how different segments behave and contribute to revenue.
  
- This segmentation helps businesses tailor strategies for marketing, retention, and customer experience improvement.

### 5. Query Optimization
In advanced stages, the focus shifts to improving query performance. Some optimization strategies include:
- **Indexing**: Adding indexes on frequently queried columns.
- **Query Execution Plan**: Using `EXPLAIN ANALYZE` to review and refine query performance.
  
---

## 30 Questions

### Easy Level
1. List all users
2. Total number of users
3. Count total orders
4. Get total number of products
5. Get unique product categories
6. List all distribution centers
7. Get top 5 most expensive products
8. Get the cheapest product
9. Get average product price
10. Count orders by status
11. Show the count of orders placed by each customer
12. Find customers who have placed more than 2 orders
13. Number of products per category
14. Total revenue generated
15. Top 5 most frequent browsers

### Medium Level
1. Find customers who haven't placed any orders
2. Top 10 selling products by revenue
3. Monthly sales trend
4. Top 10 customers by total spend
5. Total revenue generated from each category
6. Most used distribution centers
7. Most frequently ordered products
8. Average delivery time per distribution center
9. Customers who placed orders in every month of the year
10. Top 3 products with highest return rate

### Advanced Level
1. Top revenue product in each category
```sql
SELECT category, name, total_revenue
FROM (
   SELECT p.category, p.name, SUM(oi.sale_price) AS total_revenue,
   RANK() OVER(PARTITION BY p.category ORDER BY SUM(oi.sale_price) DESC) AS rank
   FROM products p
   JOIN order_items oi ON p.id = oi.product_id
   GROUP BY p.category, p.name
) ranked
WHERE rank = 1;

```

2. Find products with declining sales trend
```sql
WITH monthly_sales AS (
   SELECT p.id, p.name, DATE_TRUNC('month', o.created_at) AS month,
   SUM(oi.sale_price) AS total_sales
   FROM products p
   JOIN order_items oi ON p.id = oi.product_id
   JOIN orders o ON oi.order_id = o.order_id
   GROUP BY p.id, p.name, month
)
SELECT name
FROM monthly_sales
GROUP BY name
HAVING MAX(total_sales) > MIN(total_sales);

```

3. Basket analysis - frequently bought together
4. Bounce rate estimation: users who visited but didn't buy
5. Customer retention by repeat purchases:
```sql
SELECT
  CASE
    WHEN order_count = 1 THEN 'One-time Buyer'
	WHEN order_count BETWEEN 2 AND 5 THEN 'Repeat Buyer'
	ELSE 'Loyal Customer'
   END AS customer_type,
  COUNT(*) AS customer_count
FROM (
 SELECT user_id, COUNT(*) AS order_count
 FROM orders
 GROUP BY user_id
) AS sub
GROUP BY customer_type;

```

## Customer Segmentation
To better understand customer behavior, we segmented users based on their lifetime value (LTV) into **Low**, **Mid**, and **High** value groups using percentile thresholds. This helped identify which customers generate the most revenue and where growth opportunities lie.

#### How It Works

- All customersâ€™ total purchases were aggregated to calculate their lifetime value.
- The 25th and 75th percentiles were used to classify customers:
  - `Low-Value`: Below the 25th percentile
  - `Mid-Value`: Between the 25th and 75th percentiles
  - `High-Value`: Above the 75th percentile
- The segmentation helps identify customers that need more attention, those who are steadily contributing, and top-performing users who drive the most revenue.

#### Revenue Distribution

The chart below shows how revenue is distributed across segments:

  - `High-Value`: **60%**
  - `Mid-Value`: **36%**
  - `Low-Value`: **4%**

  ![pie_chart](https://github.com/Sankalpkombey/looker_dataset_sql_analysis/blob/main/Screenshot%202025-08-20%20005510.png)

## Query Optimisation Techniques
To improve query performance in our eCommerce project, we carried out the following optimization process:

- **Initial Query Performance Analysis Using `EXPLAIN`**

  - We began by analyzing the performance of a query that retrieved customer lifetime value (LTV) by joining the users and order_items tables. The initial query used an implicit join, which resulted in inefficient execution.
The performance metrics were as follows:

 - Execution time (E.T.): 619 ms
- Planning time (P.T.): 0.48 ms  

 Below is the **screenshot** of the `EXPLAIN` result before optimization:
 ![query_chart](https://github.com/Sankalpkombey/looker_dataset_sql_analysis/blob/main/Screenshot%202025-08-28%20010619.png)

- **Index Creation on the order_items.user_id Column**

  - To optimize query performance, we created an index on the order_items.user_id column to speed up filtering and joining operations.
SQL command for creating the index:

```sql
CREATE INDEX idx_order_items_user_id ON order_items(user_id);

```
- **Query Refactoring Using Explicit JOIN**

  - We also refactored the query to use an explicit JOIN, which allows the database planner to create a better execution plan and leverage the index effectively.
Optimized SQL query:

```sql
EXPLAIN ANALYZE
SELECT u.id, u.first_name, SUM(oi.sale_price) AS total_ltv
FROM users u
JOIN order_items oi ON u.id = oi.user_id
GROUP BY u.id, u.first_name;

```
- **Performance Analysis After Optimization**

  - After creating the index and rewriting the query, we executed it again and observed a significant reduction in execution and planning times:

    - Execution time (E.T.): 560 ms
     - Planning time (P.T.): 0.45 ms

Below is the screenshot of the EXPLAIN result after optimization:
![query_chart](https://github.com/Sankalpkombey/looker_dataset_sql_analysis/blob/main/Screenshot%202025-08-28%20010711.png)
**EXPLAIN After Index and JOIN Optimization**

This optimization shows how indexing can drastically reduce query time, improving the overall performance of our database operations in the Ecommerce project.
---

## Technology Stack
- **Database**: PostgreSQL
- **SQL Queries**: DDL, DML, Aggregations, Joins, Subqueries, Window Functions
- **Tools**: pgAdmin 4 (or any SQL editor), PostgreSQL (via Homebrew, Docker, or direct installation)

## How to Run the Project
1. Install PostgreSQL and pgAdmin (if not already installed).
2. Set up the database schema and tables using the provided normalization structure.
3. Insert the sample data into the respective tables.
4. Execute SQL queries to solve the listed problems.
5. Execute customer segmentation to categories low, mid, and high value customers
6. Explore query optimization techniques for large datasets.

---

## Next Steps
- **Visualize the Data**: Use a data visualization tool like **Tableau** or **Power BI** to create dashboards based on the query results.
- **Expand Dataset**: Add more rows to the dataset for broader analysis and scalability testing.
- **Advanced Querying**: Dive deeper into query optimization and explore the performance of SQL queries on larger datasets.

---

## Contributing
If you would like to contribute to this project, feel free to fork the repository, submit pull requests, or raise issues.

---

## License
This project is licensed under the MIT License.
